---
layout:     post                                # 使用的布局（不需要改）
title:      一口气完成Pytorch深度学习环境搭建     # 标题 
subtitle:   沐浴Anaconda的恩泽                   #副标题
date:       2020-01-22                          # 时间
author:     zhaiyunfan                          # 作者
header-img: img/post-cover-Pytorch.jpg          #这篇文章标题背景图片
catalog: true                                   # 是否归档
tags:                                           #标签
    - 深度学习
    - 教程
    - Python
    - Anaconda
    - Pytorch
---
## 前言

时间来到21世纪的第二个十年，*Python*凭借着其简单明了的语法和众多像*numpy一样*优秀的包已成为了数据科学工作者最喜爱的工具语言之一。当然，机器学习与深度学习等领域也不例外，本文从*Anaconda*(一个用于科学计算的*Python*发行版)的安装配置起，一路手把手教你如何配置属于你的*Pytorch*环境。你可以在本文结尾学会如何把你的*Pycharm*——一款久经考验的*IDE*——和你的*Anaconda*联系在一起；如果你愿意更进一步的话，你大概可以在下篇博文中邂逅*Jupyter Notebook*，感受一种全新的书写体验

### Anaconda简介

*Python*有着数量庞大的用于科学计算与数据分析的扩展包，只用*pip*指令逐个安装并管理他们之间的依赖关系是一件很困难的任务。同时，对于不同的目标，我们可能会需要不同版本、不同包搭配的*Python*，要为每一个版本单独创建一个虚拟机吗？*Anaconda*给出了否定的答案。*Anaconda*是一个用于科学计算的*Python*发行版，支持*Linux*，*Mac*，*Windows*，包含了众多流行的科学计算、数据分析的*Python*包。在它的帮助下，你可以很轻松的安装并配置众多*Python*包，同时拥有互不冲突的多套*Python*生产环境，并在他们之间迅速切换。具体来说：

>如果你需要的包要求不同版本的*Python*，你无需切换到不同的环境，因为*conda*同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的*Python*版本，同时继续在你常规的环境中使用你常用的*Python*版本。

因此，在这篇教程中，我会用它安装并配置我的生产环境

### Pytorch简介

[Pytorch](https://pytorch.org/)是一个的开源机器学习框架。2017年1月，*Facebook人工智能研究院*基于*Torch*推出了*PyTorch*。它既可以看作加入了*GPU*支持的*numpy*，同时也可以看成一个拥有自动求导功能的强大的深度神经网络。凭借着众多远胜于它众多竞争者——如*Tensorflow*和*MXNet*——的众多特性，现已在学界被大量应用。机器学习本质上是个数学问题，*Pytorch*等框架中封装良好的数学工具已极大的降低了其准入门槛与学习难度。不但如此，*Pytorch*有着对*GPU*的良好支持，只要你已经安装好*NVIDIA*公司提供的*CUDA*模块，修改一行代码，你就可以把你的代码在*CPU*和*GPU*上无痛切换，全仰赖于*Pytorch*优秀的设计。因此，在这篇教程中，我选用它配合我的学习工作

## 正文

### 安装配置Anaconda

#### 安装Anaconda

我们首先安装*Anaconda*

*Anaconda*有着它自己的[官网](https://www.anaconda.com/)，但鉴于国内复杂的网络环境，我们并不敢保证每个人都可以从它上面跑满带宽下载*Anaconda*安装包，所以我们这里选择[清华大学开源软件镜像站](https://mirror.tuna.tsinghua.edu.cn/)提供的[下载地址](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/)。你可以在此站点找到最新的*Anaconda*安装包，截止文章成文时，最新的版本为[Anaconda3-2019.10-Windows-x86_64.exe](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2019.10-Windows-x86_64.exe)，这是一个64位的*Windows*版本，如果你使用*Linux*或*MacOSX*，你可以自行下载对应的版本，此处不再赘述

一般如果你的C盘空间足够充裕 ~~默认安装完成后大概会占用6GB空间，随着使用和安装新包，这个数字可能增长到十数GB~~ ，你可以直接一路单击**NEXT**直接应用默认选项安装

需要注意的是，不论你在安装过程中选择**为所有用户安装**还是**仅为本用户安装**，你都需要严格控制你的安装路径满足以下两条原则：

1. **绝对不要包含中文**
2. **绝对不要包含空格**
3. **绝对不能包含unicode编码的字符**

![安装路径截图](http://123.57.11.126/sym/49c4caf1be5c2acdc6556918cfe435584d339df005cb0d5982186a9a56a16176.jpg)

所以如上图一般我们可以选择**为所有用户安装**，并直接安装在*C:\ProgramData\Anaconda3*目录下，

在安装过程中，还有以下界面值得注意：

![PATH实例截图](http://123.57.11.126/sym/eb37df49f90d7e0b908cc3b31e73f9466d5de31e1b28c5dffbec57976acebf3e.jpg)

而后是上面这两个选项：

第一个*Add Anaconda to my PATH environment variable*指是否把*Anaconda*加入环境变量，这涉及到能否直接在*cmd*中使用*conda、jupyter、ipython*等命令如果你希望直接在*cmd*中使用*Anaconda*，可以勾选，如果你担心更改环境变量会影响到其他程序对*Python*的调用，那么可以不勾选，同时可以在有需求时使用*Anaconda*提供的命令行工具进行操作。事实上由于*Anaconda*自带的命令行可以显示图表，功能更强，我推荐你不勾选此项，平时直接启动*Anaconda Prompt*来操作*Anaconda*

第二个*Register Anaconda as my default Python*指是否设置*Anaconda*所带的*Python*为系统默认的*Python*版本，如果你没有安装过*Python*或者没有客制化过你自己之前的*Python*，可以直接勾选，如果你希望经常使用自己之前的*Python*，可以不勾选这个选项，取决于你的需求

除此之外就没有什么太值得说的地方了，一路**NEXT**你就可以完成你的安装，之后如果你已经将其添加到了环境变量，可以打开你的*cmd*，输入：

    conda --version

如果返回类似：

    conda 4.7.12

的字样，则证明你已经安装成功了

如果你没有添加环境变量，可以在开始菜单中找到*Anaconda Prompt (Anaconda3)*这个软件，它是*Anaconda*自带的命令行，打开后输入：

    conda list

如果正常的返回了自带的包的列表，则证明你已经安装成功了，我们稍后再进一步介绍*Anaconda*开始菜单文件夹的其余软件的用途

#### 配置Anaconda

在安装完成之后，你还需要进一步配置才能安装你的*Pytorch*

因为*Anaconda*提供的服务器在国外，如果你是国内用户，首先需要更换*Anaconda*来获取快速的包下载安装体验

同样是应用清华镜像，你可以直接通过命令修改源，但这里更推荐直接修改.condarc文件来换源。*Windows*用户无法直接创建名为*.condarc*的配置文件，先在命令行中执行：

    conda config --set show_channel_urls yes

生成该文件之后在你的当前用户目录下找到.condarc文件，用记事本或*Vscode*在其中插入以下内容：

    channels:
    - defaults
    show_channel_urls: true
    default_channels:
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
    custom_channels:
    conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud

保存后即修改完成，至此*Anaconda*的配置就结束了

你可以使用*Anaconda Navigator*的图形化界面直接管理你的环境，这个比较简单直观，不再赘述

![navigator](http://123.57.11.126/sym/3fbcd883fdafd46ceb3be5a42297fa3ed0fea8b5edd9f03c297fcac1bf9440ac.jpg)

你也可以使用命令行来操作，**注意！如果你使用Anaconda的命令行，操作时最好右键以管理员身份运行，否则操作文件时可能因为权限不足而失败**，这也是有些教程中不推荐你把*Anaconda***为所有用户安装**的原因，因为此时*Anaconda*被安装到*ProgramData*目录下，新建、删除、重命名文件需要管理员权限

![以管理员身份运行](http://123.57.11.126/sym/45c7d53a243a4b1667ac9ce311ab3c5604f90854acff05ba6e6741c6bfd9c9af.jpg)

下面提供几个常用的命令，

    conda --version                                         查看conda版本
    conda -v                                                同上

    conda --help                                            获取帮助
    conda -h                                                同上
    conda update --help                                     可替换--help为-h，获取对应帮助
    conda remove --help                                     同上

    conda env list                                          查看所有环境
    conda info --envs                                       同上

    conda update --all                                      更新当前环境所有包

    conda create --name your_env_name                       创建一个名为your_env_name的环境   
    conda create -n your_env_name                           同上
    conda create -n your_env_name python=3.7                创建一个包含指定包的环境，指定特殊版本只需加上=x.x
    conda create -n your_env_name python=3.7 numpy pandas   可以指定多个包，用空格隔开，用=表明版本号

    conda remove -n your_env_name --all                     删除名为your_env_name的环境

    activate your_env_name                                  激活并进入名为your_env_name的环境
    deactivate                                              退出到base环境

    conda list                                              列举当前环境下的所有包
    conda list -n packagename                               列举某个特定名称包
    conda install packagename                               为当前环境安装某包
    conda install -n envname packagename                    为某环境安装某包
    conda search packagename                                搜索某包
    conda updata packagename                                更新当前环境某包
    conda update -n envname packagename                     更新某特定环境某包
    conda remove packagename                                删除当前环境某包
    conda remove -n envname packagename                     删除某环境环境某包

    conda update conda                                      更新conda本体，以下同理
    conda update anaconda
    conda update python

### 安装CUDA（如果你有NVIDIA独立显卡）

>深度学习是模拟人脑神经系统而建立的数学网络模型，这个模型的最大特点是，需要大数据来训练。因此，对电脑处理器的要求，就是需要大量的并行的重复计算，GPU正好有这个专长，时势造英雄，因此，GPU就出山担当重任了。

GPU具有如下特点：

1. 提供了多核并行计算的基础结构，且核心数非常多，可以支撑大量数据的并行计算。并行计算或称平行计算是相对于串行计算来说的。它是一种一次可执行多个指令的算法，目的是提高计算速度，及通过扩大问题求解规模，解决大型而复杂的计算问题
2. 拥有更高的访存速度
3. 更高的浮点运算能力。浮点运算能力是关系到处理器的多媒体、3D图形处理的一个重要指标。现在的计算机技术中，由于大量多媒体技术的应用，浮点数的计算大大增加了，比如3D图形的渲染等工作，因此浮点运算的能力是考察处理器计算能力的重要指标

因此，GPU非常适合深度学习，而*Pytorch*又提供了非常成熟的*GPU*版本，这依赖于*NVIDIA*公司提供的*CUDA*框架，因此，即使你手中的计算机仅仅有一张**MX150**，我也推荐你安装*GPU*版本的*Pytorch*

>你可以在[*CUDA官网*](https://developer.nvidia.com/cuda-gpus)查询你的*GPU*是否支持*CUDA*和支持的最高版本，并下载安装对应版本的*CUDA*。*Pytorch*目前支持*CUDA 9.2和CUDA 10.1*，下一节以*CUDA 10.1*为例

---

使用*Anaconda*的*conda*指令是不需要额外手动安装*CUDA*的，但如果你想玩一下*CUDA*编程，可以参考下文：

首先，**你的电脑上最好已经预装了VisualStudio**，否则*CUDA*可能安装失败 ~~莫名其妙的BUG~~ ，在[官方下载地址](https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal)可以下载到*CUDA 10.1*，下载完成后一路**NEXT**即可完成安装，如果安装过程中出现不影响安装继续进行的异常，无需调试直接确定即可，此处不再赘述

---

### 安装Pytorch

现在可以开始安装*Pytorch*了，在*conda*中，如果你需要安装一个包，系统将自动检查这个包需要的前置的依赖包并且它们全部有序安装，这使得我们可以非常方便的安装我们需要的每个包

首先打开以管理员身份运行*Anaconda Prompt*，默认会直接进入*base*环境，这是*Anaconda*的*root*环境，出厂即携带大量的科学计算用包，为了加快环境的运行速度，我们单独创建一个新环境，使用命令:

    conda create -n forPytorch python=3.7

来创建一个名为*forPytorch*的，*Python*版本为3.7的新环境

![创建环境01](http://123.57.11.126/sym/5e530a54bbe98087088abc3124999afc8cbf0780dbc55c007739fd2fe561a6fb.jpg)

如图所示，*Anaconda*会自动分析所需安装的包并为你罗列出来，输入*y*来确认创建安装:

![创建环境02](http://123.57.11.126/sym/447c29959df8382a1167359c153e5fa9db686432229dc92acbbc7609c3e57d5a.jpg)

如无报错信息则为安装成功，现在切换到新创建的环境中，使用命令：

    activate forPytorch

执行后发现命令行括号内的内容从*base*变为*forPytorch*，说明现在已在新创建的环境下，从[*Pytorch*官网](https://pytorch.org/)查阅到安装命令为：

    conda install pytorch torchvision cudatoolkit=10.1 -c pytorch   #推荐 GPU版本 安装CUDA10.1  可以使用GPU或CPU
    conda install pytorch torchvision cudatoolkit=9.2 -c pytorch -c defaults -c numba/label/dev #GPU版本 安装CUDA9.2    可以使用GPU或CPU 
    conda install pytorch torchvision cpuonly -c pytorch    #非常不推荐 仅CPU版本   只能使用CPU，效率很低

分析完成后同理输入*y*确认安装，等待安装完成即可。现在你的*Anaconda*安装路径下此环境的*Python*中已经可以正常使用*Pytorch*框架，想要验证安装，你可以在该环境下的命令行中先后输入：

    python
    import torch

未报错即为安装正常

### 配置IDE

仅仅安装完了包显然还是没办法写代码的，你还需要在*IDE*或编辑器中应用新建的*Anaconda*环境中的*Python*解释器，来使用这个环境中的*Python*，对于初学者来说，这里我暂时推荐你使用*Pycharm*，最好用的*Python IDE*。它的专业版是付费的，但你可以在[官网](https://www.jetbrains.com/zh/student/)直接用你的学生邮箱来申请免费使用全套*JetBrains*开发工具，这里不再赘述

在你安装好你的*Pycharm*后，请先创建一个新工程（而非对整个*Pycharm*应用解释器的修改，这很容易造成糟糕的影响），接着在*File*栏下找到设置选项*Setting*

![setting](http://123.57.11.126/sym/d2b4bd503ed69d22480afd861645510ccb6f792b621314e080ee995ba54dbba7.jpg)

接着找到*Project*栏下的*Project Interpreter*项，右侧的下拉菜单是你当前的解释器的选择栏，点击它下面的加号，并选择*Show All...*来显示所有备选项：

![interpreter](http://123.57.11.126/sym/802807e92352e3c3a8015facdcd70db9b1c49fcda16e83e4d30fc68666b025f0.jpg)

接着点击新界面里的加号，来添加一个备选解释器：

![add02](http://123.57.11.126/sym/a41653c192a7528212410ebe2d8c675a3eef080d9f8d1d78ed33003c7180afd6.jpg)

在新界面的左侧选择*Conda Environment*来引入一个*Anaconda*环境，右侧选中下方的*Existing environment*来引入刚刚已经创建好的环境，*Interpreter*一栏中找到你*Anaconda*安装目录下的*envs\forPytorch*目录中的*Python.exe*，这是你已安装好*Pytorch*的新环境自己独有的*Python*解释器，**注意一定不要选择*Anaconda*根目录下的那个解释器，使用该解释器可能需要你每次都启动命令行并激活你自建的环境才能正常使用*Pytorch***

![add02](http://123.57.11.126/sym/c5bb6acde3f2a04d52e043e24d8bd406dbd5a6c65389cabbbdc79c14a8bd43a0.jpg)

点击确定，回到上个界面会发现该环境里安装的包都已经被*IDE*分析完毕展示出来，再确认一次即完成了所有配置

![commit](http://123.57.11.126/sym/d1ddb0f0c9cc157d562059837df8b9fb4ffc0f50b9191d4e26aa7dca6350e1aa.jpg)

现在你可以随便输入一段例程来测试一下你的新解释器，比如下面这段:

    # Code in file autograd/two_layer_net_autograd.py
    import torch
    
    # device = torch.device('cpu')
    device = torch.device('cuda') # Uncomment this to run on GPU
    
    # N is batch size; D_in is input dimension;
    # H is hidden dimension; D_out is output dimension.
    N, D_in, H, D_out = 64, 1000, 100, 10
    
    # Create random Tensors to hold input and outputs
    x = torch.randn(N, D_in, device=device)
    y = torch.randn(N, D_out, device=device)
    
    # Create random Tensors for weights; setting requires_grad=True means that we
    # want to compute gradients for these Tensors during the backward pass.
    w1 = torch.randn(D_in, H, device=device, requires_grad=True)
    w2 = torch.randn(H, D_out, device=device, requires_grad=True)
    
    learning_rate = 1e-6
    for t in range(500):
    # Forward pass: compute predicted y using operations on Tensors. Since w1 and
    # w2 have requires_grad=True, operations involving these Tensors will cause
    # PyTorch to build a computational graph, allowing automatic computation of
    # gradients. Since we are no longer implementing the backward pass by hand we
    # don't need to keep references to intermediate values.
    y_pred = x.mm(w1).clamp(min=0).mm(w2)
    
    # Compute and print loss. Loss is a Tensor of shape (), and loss.item()
    # is a Python number giving its value.
    loss = (y_pred - y).pow(2).sum()
    print(t, loss.item())
    
    # Use autograd to compute the backward pass. This call will compute the
    # gradient of loss with respect to all Tensors with requires_grad=True.
    # After this call w1.grad and w2.grad will be Tensors holding the gradient
    # of the loss with respect to w1 and w2 respectively.
    loss.backward()
    
    # Update weights using gradient descent. For this step we just want to mutate
    # the values of w1 and w2 in-place; we don't want to build up a computational
    # graph for the update steps, so we use the torch.no_grad() context manager
    # to prevent PyTorch from building a computational graph for the updates
    with torch.no_grad():
        w1 -= learning_rate * w1.grad
        w2 -= learning_rate * w2.grad
    
        # Manually zero the gradients after running the backward pass
        w1.grad.zero_()
        w2.grad.zero_()

输出一切正常就代表你完成了整个配置过程，congratulation！

---

## 后记

*Pytorch*的环境配置还是非常非常友好的，和*Python*一脉相承的护发，~~然而Anaconda实在太有意思，好多东西没说很细还是写了300行Markdown~~ ，相关的资料都非常成熟了，也没上一篇博文那沙雕框架那么多坑 ~~天灭PHP~~

下一篇打算写一下*Jupyter Notebook*的使用技巧，马上过年了，这两天会比较忙，明天 ~~今天~~ 起床还得回学校把电脑搬回家，可能来不及更新博文，该学还是会学的，*Pytorch*真香

世界晚安

>zhaiyunfan 2020-01-22 03:00
